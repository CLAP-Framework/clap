#!/usr/bin/env python

import rospy
import numpy as np
import threading

from sensor_msgs.msg import CameraInfo
from zzz_perception_msgs.msg import DetectionBox2DArray, DetectionBoxArray, DetectionBox, DetectionBox2D
from zzz_common.params import parse_private_args, IntrinsicListener
from zzz_perception_detection_camera_filters.projection import InversePerspectiveMapping

class IPMNode():
    def __init__(self):
        params = parse_private_args(
            input_topic="objects2d_detected",
            output_topic="objects_projected",
            camera_height=1.27, # FIXME: read height from extrinsics. Need a way to associate height from any of the frames
        )

        self._sub = rospy.Subscriber(params.input_topic, DetectionBox2DArray, self.obj_callback)
        self._intri_buffer = IntrinsicListener()
        self._pub = rospy.Publisher(params.output_topic, DetectionBoxArray, queue_size=1)

        self._default_height = 2
        self._default_width = 2
        self._default_length = 2

        # initialize camera geometry model
        self._mapping = InversePerspectiveMapping(height=params.camera_height)
        self._intri_received = False

    def obj_callback(self, detections):
        # Look up camera intrinsics
        intri = self._intri_buffer.lookupCameraInfo(detections.header.frame_id)
        if not intri:
            rospy.logdebug("Skipped frame since no camera intrinsics is received.")
            return
        self._mapping.setIntrinsics(cx=intri.K[2], cy=intri.K[5], fx=intri.K[0], fy=intri.K[4])

        array = DetectionBoxArray()
        for det in detections.detections:
            # Use the bottom center of the bounding box to calculate location
            u = np.array([det.bbox.pose.x])
            v = np.array([det.bbox.pose.y + det.bbox.dimension.length_y / 2.])
            lo, la = self._mapping.img2world(u, v)
            
            newdet = DetectionBox()
            newdet.bbox.pose.pose.position.x = lo[0]
            newdet.bbox.pose.pose.position.y = -la[0]
            newdet.bbox.pose.pose.position.z = self._default_height / 2. # assume the object is on the ground
            # TODO: unify covariance representation for infinity
            # TODO: calculate x y covariance from image location uncertainty (and height uncertainty?)
            newdet.bbox.pose.covariance = np.diag([2,2,1e6,1e6,1e6,1e6]).flatten().tolist()
            
            newdet.bbox.dimension.length_x = self._default_width
            newdet.bbox.dimension.length_y = self._default_length
            newdet.bbox.dimension.length_z = self._default_height
            newdet.bbox.dimension.covariance = np.diag([1] * 3).flatten().tolist()

            newdet.classes = det.classes
            array.detections.append(newdet)

        array.header = detections.header
        self._pub.publish(array)

if __name__ == "__main__":
    rospy.init_node("ipm_projector")
    node = IPMNode()
    rospy.spin()
