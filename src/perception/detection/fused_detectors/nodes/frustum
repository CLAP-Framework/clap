#!/usr/bin/env python

import rospy
from cv_bridge import CvBridge

from zzz_common.params import parse_private_args
from frustum_pointnets.module_wrapper.frustum_module import FrustumModule

from sensor_msgs.msg import Image, PointCloud2, PointField, CameraInfo
from zzz_perception_msgs.msg import DetectionBox2DArray, DetectionBox2D, DetectionBoxArray, DetectionBox, BoundingBox, ObjectClass

import message_filters

import pseudo_lidar.preprocessing.cam_velo_utils as cam_velo_utils

import os
import numpy as np
import pcl
import time
# import ros_numpy

def msg_detections_2d_to_bbox_and_labels(message_detection_2d):
    detections_2d = message_detection_2d.detections
    boxes = []
    labels = []
    for detection_2d in detections_2d:
        box_2d = detection_2d.bbox
        x_center = box_2d.pose.x
        y_center = box_2d.pose.y
        x_dim = box_2d.dimension.length_x
        y_dim = box_2d.dimension.length_y
        x_min = x_center - x_dim/2.
        x_max = x_center + x_dim/2.
        y_min = y_center - y_dim/2.
        y_max = y_center + y_dim/2.
        box = [x_min, y_min, x_max, y_max]
        boxes.append(box)

        cls_detect = detection_2d.classes[0].classid
        if np.bitwise_and(cls_detect, 1):
            cls_string = "Car"
        elif np.bitwise_and(cls_detect, 2):
            cls_string = "Pedestrian"
        elif np.bitwise_and(cls_detect, 3):
            cls_string = "Cyclist"
        else:
            cls_string = "Car"

        labels.append(cls_string)

    return boxes, labels

def generate_3d_detection_msg(hs, ws, ls, txs, tys, tzs, rys, type_list):
    msg_detects_3d = DetectionBoxArray()
    msg_detects_3d.header.frame_id = "ego_vehicle"
    for i in range(len(hs)):
        detect_3d = DetectionBox()
        detect_3d.bbox.pose.pose.position.x = tzs[i]
        detect_3d.bbox.pose.pose.position.y = -txs[i]
        detect_3d.bbox.pose.pose.position.z = -tys[i]
        detect_3d.bbox.pose.pose.orientation.x = 0
        detect_3d.bbox.pose.pose.orientation.y = 0
        detect_3d.bbox.pose.pose.orientation.z = -np.sin(rys[i]/2.)
        detect_3d.bbox.pose.pose.orientation.w = np.cos(rys[i]/2.)
        detect_3d.bbox.dimension.length_x = hs[i]
        detect_3d.bbox.dimension.length_y = ls[i]
        detect_3d.bbox.dimension.length_z = ws[i]
        obj_class = ObjectClass()
        if type_list[i] == "Car":
            obj_class.classid = 1
        elif type_list[i] == "DetectionBoxArrayPedestrian":
            obj_class.classid = 2
        elif type_list[i] == "Cyclist":
            obj_class.classid = 3
        obj_class.comments = type_list[i]
        detect_3d.classes.append(obj_class)

        msg_detects_3d.detections.append(detect_3d)
    return msg_detects_3d

        
        
        
        
        

class Detection3dOnLidar(object):
    def __init__(self):
        params = parse_private_args(
            input_camera_topic="/zzz/drivers/image_raw",
            input_topic_lidar="/zzz/drivers/image_raw",
            camera_info_topic="/zzz/drivers/camera_info",
            input_2ddection_topic="", 
            output_topic="objects_detected",
            target_frame="base_link", # TODO: which frame
            gpu=1,
            num_point=1024, # 1024
            model='frustum_pointnets_v1',
            model_path=os.environ.get('ZZZ_ROOT') + '/src/perception/detection/fused_detectors/src/frustum_pointnets/train/log_v1_pseudo/model.ckpt',
            batch_size=32,
            output='test_results',
            from_rgb_detection=True,
            idx_path=None,
            dump_result=False
        )

        # network initialization
        self.frustum_3d_detector = FrustumModule(params)

        self._bridge = CvBridge()
        
        self._publisher = rospy.Publisher(params.pop("output_topic"), DetectionBoxArray, queue_size=1)

        image_sub = message_filters.Subscriber(params.input_camera_topic, Image)
        info_left_sub = message_filters.Subscriber(params.camera_info_topic, CameraInfo)
        lidar_sub = message_filters.Subscriber(params.input_topic_lidar, PointCloud2)
        detection_2d_sub = message_filters.Subscriber(params.input_2ddection_topic, DetectionBox2DArray)

        # img_cache = message_filters.Cache(image_sub, 30)
        # lidar_cache = message_filters.Cache(lidar_sub, 30)
        # info_left_sub = message_filters.Cache(info_left_sub, 30)

        ts = message_filters.TimeSynchronizer([image_sub, lidar_sub, detection_2d_sub, info_left_sub], 20) # TODO: the four message does not come at the same time
        ts.registerCallback(self.callback)

    def callback(self, msg_image_left, msg_lidar, message_detection_2d, info_cam_left):
        # process messages
        self._image_left = self._bridge.imgmsg_to_cv2(msg_image_left, "bgr8")
        imgL_o = self._image_left.astype('float32')

        self.K_left = info_cam_left.K
        calib = cam_velo_utils.Calibration(self.K_left)

        # pcl_array = ros_numpy.point_cloud2.pointcloud2_to_array(msg_lidar)
        # pcs_xyz = ros_numpy.point_cloud2.get_xyz_points(pcl_array).transpose() # float32
        # pcs_color = ros_numpy.point_cloud2.split_rgb_field(pcl_array).astype(np.float32)
        # pcs_intensity = 0.3*pcs_color['r'] + 0.59 * pcs_color['g'] + 0.11 * pcs_color['b']
        # pcs_in = np.stack((pcs_xyz, pcs_intensity), axis=1)

        ori_cloud = pcl.PointCloud(msg_lidar)
        cloud = ori_cloud.xyz # TODO: Fix this in pcl.py

        arr = ori_cloud.to_ndarray()
        ndtype = {'names':['rgb'], 'formats':['3u1'], 'offsets':[12], 'itemsize':arr.dtype.itemsize}
        cloud_rgb = arr.view(ndtype)['rgb']
        
        cloud_intensity = 0.2989 * cloud_rgb[:,0] + 0.5870 * cloud_rgb[:,1] + 0.1140 * cloud_rgb[:,2]
        # pcs_in = np.hstack((cloud, np.ones((cloud.shape[0], 1))))
        pcs_in = np.hstack((cloud, cloud_intensity.reshape(-1,1)))

        boxes_2d, labels = msg_detections_2d_to_bbox_and_labels(message_detection_2d)
        
        start_time = time.time()
        # run 3d detection given inputs
        hs, ws, ls, txs, tys, tzs, rys, type_list = \
            self.frustum_3d_detector.run(pcs_in, imgL_o, labels, boxes_2d, calib) # pcs_in is n*4 np array
        print('time for 3d detection on pseudo lidar= %.2f' %(time.time() - start_time))

        if len(hs) == 0:
            msg_detections_3d = DetectionBoxArray()
        else:
            msg_detections_3d = generate_3d_detection_msg(hs, ws, ls, txs, tys, tzs, rys, type_list)

        msg_detections_3d.header = msg_image_left.header

        self._publisher.publish(msg_detections_3d)

if __name__ == '__main__':
    rospy.init_node('frustum_detector')
    Detection3dOnLidar()
    rospy.spin()
