#!/usr/bin/env python

# General imports
import os
import os.path as osp
import sys
import math
import random
import numpy as np
from numpy.lib.recfunctions import structured_to_unstructured

# ROS imports
import rospy
from std_msgs.msg import String
from sensor_msgs.msg import PointCloud2
from zzz_perception_msgs.msg import DetectionBoxArray, DetectionBox, ObjectClass
from zzz_common.params import parse_private_args

import pcl
import time

# SECOND imports
from google.protobuf import text_format
from pathlib import Path

import torchplus
import second.data.kitti_common as kitti
from second.builder import target_assigner_builder, voxel_builder
from second.core import box_np_ops
from second.data.preprocess import merge_second_batch, prep_pointcloud
from second.protos import pipeline_pb2
from second.pytorch.builder import (box_coder_builder, input_reader_builder,
                                    lr_scheduler_builder, optimizer_builder,
                                    second_builder)
from second.pytorch.train import predict_to_kitti_label, example_convert_to_torch

class Node:
    def __init__(self):
        params = parse_private_args(
            config_path='/home/jacobz/temp_ws/zzz_second/second/configs/car.lite.config',
            ckpt_path='/home/jacobz/temp_ws/zzz_second/pretrained_models_v1.5/car_lite/voxelnet-15500.tckpt'
        )

        self.subscriber = rospy.Subscriber("/kitti/velo/pointcloud", PointCloud2, self.lidar_callback, queue_size=1)
        self._model = SecondModel(params.config_path, params.ckpt_path)
    
    def lidar_callback(self, msg):
        cloud = pcl.PointCloud(msg)
        for field in cloud.fields:
            if field.name == "i" or field.name == "intensity":
                intensity_fname = field.name
                intensity_dtype = field.datatype
            else:
                intensity_fname = None
                intensity_dtype = None
            
        pc_arr = cloud.to_ndarray()
        if intensity_fname:
            pc_arr = structured_to_unstructured(pc_arr[["x", "y", "z", intensity_fname]]).copy()
            if intensity_dtype == 2:
                pc_arr[:, 3] = pc_arr[:, 3] / 255
        else:
            pc_arr = structured_to_unstructured(pc_arr[["x", "y", "z"]]).copy()
            pc_arr = np.hstack((pc_arr, np.zeros((pc_arr.shape[0], 1))))

        lidar_boxes = self._model.predcit(pc_arr)
        print(lidar_boxes)
        
        '''
        num_detects = len(lidar_boxes)
        arr_bbox = BoundingBoxArray()
        for i in range(num_detects):
            bbox = BoundingBox()

            bbox.header.frame_id = msg.header.frame_id
            bbox.header.stamp = rospy.Time.now()

            bbox.pose.position.x = float(lidar_boxes[i][0])
            bbox.pose.position.y = float(lidar_boxes[i][1])
            bbox.pose.position.z = float(lidar_boxes[i][2]) + float(lidar_boxes[i][5]) / 2
            bbox.dimensions.x = float(lidar_boxes[i][3])  # width
            bbox.dimensions.y = float(lidar_boxes[i][4])  # length
            bbox.dimensions.z = float(lidar_boxes[i][5])  # height

            q = Quaternion(axis=(0, 0, 1), radians=float(lidar_boxes[i][6]))
            bbox.pose.orientation.x = q.x
            bbox.pose.orientation.y = q.y
            bbox.pose.orientation.z = q.z
            bbox.pose.orientation.w = q.w

            arr_bbox.boxes.append(bbox)

        arr_bbox.header.frame_id = msg.header.frame_id
        arr_bbox.header.stamp = rospy.Time.now()
        print("Number of detections: {}".format(num_detects))
        
        self.pub_bbox.publish(arr_bbox)
        '''


class InferenceContext:
    def __init__(self):
        self.config = None
        self.target_assigner = None
        self.voxel_generator = None
        self.anchor_cache = None
        self.built = False
        self.net = None
        self.anchor_cache = None

    def get_inference_input_dict(self, points):
        assert self.anchor_cache is not None
        assert self.target_assigner is not None
        assert self.voxel_generator is not None
        assert self.config is not None
        assert self.built is True

        input_cfg = self.config.eval_input_reader
        model_cfg = self.config.model.second

        input_dict = {
            'points': points,
        }
        out_size_factor = np.prod(model_cfg.rpn.layer_strides)
        if len(model_cfg.rpn.upsample_strides) > 0:
            out_size_factor /= model_cfg.rpn.upsample_strides[-1]
        out_size_factor *= model_cfg.middle_feature_extractor.downsample_factor
        out_size_factor = int(out_size_factor)
        example = prep_pointcloud(
            input_dict=input_dict,
            voxel_generator=self.voxel_generator,
            target_assigner=self.target_assigner,
            max_voxels=input_cfg.max_number_of_voxels,
            class_names=self.target_assigner.classes,
            training=False,
            create_targets=False,
            shuffle_points=input_cfg.shuffle_points,
            generate_bev=False,
            without_reflectivity=model_cfg.without_reflectivity,
            num_point_features=model_cfg.num_point_features,
            anchor_area_threshold=input_cfg.anchor_area_threshold,
            anchor_cache=self.anchor_cache,
            out_size_factor=out_size_factor,
            out_dtype=np.float32)
        example["metadata"] = {}
        if "anchors_mask" in example:
            example["anchors_mask"] = example["anchors_mask"].astype(np.uint8)

        # convert example to batched example
        example = merge_second_batch([example])
        return example

    def get_config(self, path):
        '''
        Read config from file
        '''
        config = pipeline_pb2.TrainEvalPipelineConfig()
        with open(path, "r") as f:
            proto_str = f.read()
            text_format.Merge(proto_str, config)
        return config

    def build(self, config_path):
        '''
        Build inference context
        '''
        self.config = self.get_config(config_path)
        # input_cfg = self.config.eval_input_reader
        model_cfg = self.config.model.second
        train_cfg = self.config.train_config
        # batch_size = 1
        self.voxel_generator = voxel_builder.build(model_cfg.voxel_generator)
        bv_range = self.voxel_generator.point_cloud_range[[0, 1, 3, 4]]
        grid_size = self.voxel_generator.grid_size
        # vfe_num_filters = list(model_cfg.voxel_feature_extractor.num_filters)

        box_coder = box_coder_builder.build(model_cfg.box_coder)
        target_assigner_cfg = model_cfg.target_assigner
        target_assigner = target_assigner_builder.build(
            target_assigner_cfg, bv_range, box_coder)
        self.target_assigner = target_assigner
        out_size_factor = model_cfg.rpn.layer_strides[0] / model_cfg.rpn.upsample_strides[0]
        out_size_factor *= model_cfg.middle_feature_extractor.downsample_factor
        out_size_factor = int(out_size_factor)
        self.net = second_builder.build(model_cfg, self.voxel_generator,
                                          target_assigner)
        self.net.cuda().eval()
        if train_cfg.enable_mixed_precision:
            self.net.half()
            self.net.metrics_to_float()
            self.net.convert_norm_to_float(self.net)
        feature_map_size = grid_size[:2] // out_size_factor
        feature_map_size = [1] + list(feature_map_size)[::-1] # [*feature_map_size, 1][::-1]
        ret = target_assigner.generate_anchors(feature_map_size)
        anchors_dict = target_assigner.generate_anchors_dict(feature_map_size)
        anchors = ret["anchors"]
        anchors = anchors.reshape([-1, 7])
        matched_thresholds = ret["matched_thresholds"]
        unmatched_thresholds = ret["unmatched_thresholds"]
        anchors_bv = box_np_ops.rbbox2d_to_near_bbox(
            anchors[:, [0, 1, 3, 4, 6]])
        anchor_cache = {
            "anchors": anchors,
            "anchors_bv": anchors_bv,
            "matched_thresholds": matched_thresholds,
            "unmatched_thresholds": unmatched_thresholds,
            "anchors_dict": anchors_dict,
        }
        self.anchor_cache = anchor_cache
        self.built = True

    def inference(self, example):
        # train_cfg = self.config.train_config
        # input_cfg = self.config.eval_input_reader
        model_cfg = self.config.model.second
        example_torch = example_convert_to_torch(example)
        result_annos = predict_to_kitti_label(
            self.net, example_torch, list(
                self.target_assigner.classes),
            model_cfg.post_center_limit_range, model_cfg.lidar_input)
        return result_annos

    def restore(self, ckpt_path):
        ckpt_path = Path(ckpt_path)
        assert ckpt_path.suffix == ".tckpt"
        torchplus.train.restore(str(ckpt_path), self.net)

class SecondModel:
    def __init__(self, config_path, ckpt_path):
        self.config_path = config_path
        self.ckpt_path = ckpt_path
        self.inference_ctx = None
        
        self._build()
        self._restore()
    
    def predcit(self, pointclouds):
        t = time.time()
        result_annos = self._inference(pointclouds)
        print("Inference time: %.2f ms" % ((time.time() - t) * 1000))
        kitti_anno = self.remove_low_score(result_annos[0])

        return kitti_anno
    
    def _build(self):
        print("Start build...")
        self.inference_ctx = InferenceContext()
        self.inference_ctx.build(self.config_path)
        print("Build succeeded.")

    def _restore(self):
        print("Start restore...")
        self.inference_ctx.restore(self.ckpt_path)
        print("Restore succeeded.")

    def _inference(self, pointclouds):
        inputs = self.inference_ctx.get_inference_input_dict(pointclouds)
        det_annos = self.inference_ctx.inference(inputs)
        return det_annos

    def remove_low_score(self, annos, threshold=0.5):
        img_filtered_annotations = {}
        relevant_annotation_indices = [i for i, s in enumerate(annos['score']) if s >= threshold]
        for key in annos.keys():
            img_filtered_annotations[key] = (annos[key][relevant_annotation_indices])

        return img_filtered_annotations

if __name__ == '__main__':
    rospy.init_node('second_detector')
    Node()
    rospy.spin()
