#!/usr/bin/env python

import zzz_driver_datasets_kitti as driver

import sys
import os
import tqdm
import argparse
import json
from itertools import izip

import tf
import cv2
from cv_bridge import CvBridge
import numpy as np

import rospy
import rosbag

from tf2_msgs.msg import TFMessage
from std_msgs.msg import Header
from sensor_msgs.msg import CameraInfo, Imu, PointField, NavSatFix
import sensor_msgs.point_cloud2 as pcl2
from geometry_msgs.msg import TransformStamped, TwistStamped, Transform

def save_imu_data(bag, kitti, imu_frame_id, topic):
    print("Exporting IMU...")
    for timestamp, oxts in tqdm.tqdm(izip(kitti.oxts_timestamps, kitti.oxts), unit="Frame",
        desc="Writing IMU", leave=False, dynamic_ncols=True, total=len(kitti.oxts_timestamps)):
        q = tf.transformations.quaternion_from_euler(oxts.packet.roll, oxts.packet.pitch, oxts.packet.yaw)
        imu = Imu()
        imu.header.frame_id = imu_frame_id
        imu.header.stamp = rospy.Time.from_sec(timestamp.astype('O') / 1e9)
        imu.orientation.x = q[0]
        imu.orientation.y = q[1]
        imu.orientation.z = q[2]
        imu.orientation.w = q[3]
        imu.linear_acceleration.x = oxts.packet.af
        imu.linear_acceleration.y = oxts.packet.al
        imu.linear_acceleration.z = oxts.packet.au
        imu.angular_velocity.x = oxts.packet.wf
        imu.angular_velocity.y = oxts.packet.wl
        imu.angular_velocity.z = oxts.packet.wu
        bag.write(topic, imu, t=imu.header.stamp)

def save_dynamic_tf(bag, kitti, kitti_type):
    print("Exporting transformations...")
    # TODO: combine redundant code (like save_camera_data)
    if kitti_type == "sync" or kitti_type == "extract": # raw data
        for timestamp, oxts in tqdm.tqdm(izip(kitti.oxts_timestamps, kitti.oxts), unit="Frame",
            desc="Writing transform", leave=False, dynamic_ncols=True, total=len(kitti.oxts_timestamps)):
            tf_oxts_msg = TFMessage()
            tf_oxts_transform = TransformStamped()
            tf_oxts_transform.header.stamp = rospy.Time.from_sec(timestamp.astype('O') / 1e9)
            tf_oxts_transform.header.frame_id = 'world'
            tf_oxts_transform.child_frame_id = 'base_link'

            transform = (oxts.T_w_imu)
            t = transform[0:3, 3]
            q = tf.transformations.quaternion_from_matrix(transform)
            oxts_tf = Transform()

            oxts_tf.translation.x = t[0]
            oxts_tf.translation.y = t[1]
            oxts_tf.translation.z = t[2]

            oxts_tf.rotation.x = q[0]
            oxts_tf.rotation.y = q[1]
            oxts_tf.rotation.z = q[2]
            oxts_tf.rotation.w = q[3]

            tf_oxts_transform.transform = oxts_tf
            tf_oxts_msg.transforms.append(tf_oxts_transform)

            bag.write('/tf', tf_oxts_msg, tf_oxts_msg.transforms[0].header.stamp)
    elif kitti_type == "odometry": # odometry data
        for timestamp, tf_matrix in zip(kitti.timestamps, kitti.poses):
            tf_msg = TFMessage()
            tf_stamped = TransformStamped()
            tf_stamped.header.stamp = rospy.Time.from_sec(timestamp.astype('O') / 1e9)
            tf_stamped.header.frame_id = 'world'
            tf_stamped.child_frame_id = 'camera_left'
            
            t = tf_matrix[0:3, 3]
            q = tf.transformations.quaternion_from_matrix(tf_matrix)
            transform = Transform()

            transform.translation.x = t[0]
            transform.translation.y = t[1]
            transform.translation.z = t[2]

            transform.rotation.x = q[0]
            transform.rotation.y = q[1]
            transform.rotation.z = q[2]
            transform.rotation.w = q[3]

            tf_stamped.transform = transform
            tf_msg.transforms.append(tf_stamped)

            bag.write('/tf', tf_msg, tf_msg.transforms[0].header.stamp)
        
def save_camera_data(bag, kitti, kitti_type, camera, camera_frame_id, topic):
    print("Exporting camera {}...".format(camera))
    bridge = CvBridge()
    image_datetimes = getattr(kitti, "cam%d_timestamps" % camera)
    image_data = getattr(kitti, "cam%d" % camera)

    calib = CameraInfo()
    calib.header.frame_id = camera_frame_id
    if kitti_type == "sync" or : # raw data, synced and rectified
        calib.width, calib.height = kitti.calib['S_rect_0%d' % camera].tolist()
        calib.distortion_model = 'plumb_bob'
        calib.K = kitti.calib['K_0%d' % camera].reshape(-1)
        calib.R = kitti.calib['R_rect_0%d' % camera].reshape(-1)
        calib.D = kitti.calib['D_0%d' % camera].reshape(-1)
        calib.P = kitti.calib['P_rect_0%d' % camera].reshape(-1)

    elif kitti_type == "extract": # raw data, unsynced and unrectified
        calib.width, calib.height = kitti.calib['S_0%d' % camera].tolist()
        calib.distortion_model = 'plumb_bob'
        calib.K = kitti.calib['K_0%d' % camera].reshape(-1)
        calib.R = kitti.calib['R_0%d' % camera].reshape(-1)
        calib.D = kitti.calib['D_0%d' % camera].reshape(-1)
        calib.P = kitti.calib['P_0%d' % camera].reshape(-1)
            
    elif kitti_type == "odometry": # odometry data
        calib.P = kitti.calib['P%d' % camera].reshape(-1)
    
    for timestamp, image in tqdm.tqdm(izip(image_datetimes, image_data), unit="Frame",
        desc="Writing Cam%d" % camera, leave=False, dynamic_ncols=True, total=len(image_datetimes)):
        image = np.array(image)
        calib.height, calib.width = image.shape[:2]
        encoding = "mono8" if camera in (0, 1) else "rgb8"

        image_message = bridge.cv2_to_imgmsg(image, encoding=encoding)
        image_message.header.frame_id = camera_frame_id
        image_message.header.stamp = rospy.Time.from_sec(timestamp.astype('O') / 1e9)
        if hasattr(kitti, 'oxts'):
            topic_ext = "/image_raw"
        elif kitti_type.find("odom") != -1:
            topic_ext = "/image_rect"

        calib.header.stamp = image_message.header.stamp
        bag.write(topic + topic_ext, image_message, t = image_message.header.stamp)
        bag.write(topic + '/camera_info', calib, t = calib.header.stamp) 
        
def save_velo_data(bag, kitti, velo_frame_id, topic):
    print("Exporting velodyne data...")
    for timestamp, scan in tqdm.tqdm(izip(kitti.velo_timestamps, kitti.velo), unit="Frame",
        desc="Writing velodyne", leave=False, dynamic_ncols=True, total=len(kitti.velo_timestamps)):
        # create header
        header = Header()
        header.frame_id = velo_frame_id
        header.stamp = rospy.Time.from_sec(timestamp.astype('O') / 1e9)

        # fill pcl msg
        fields = [PointField('x', 0, PointField.FLOAT32, 1),
                  PointField('y', 4, PointField.FLOAT32, 1),
                  PointField('z', 8, PointField.FLOAT32, 1),
                  PointField('intensity', 12, PointField.FLOAT32, 1)]
        pcl_msg = pcl2.create_cloud(header, fields, scan)

        bag.write(topic + '/pointcloud', pcl_msg, t=pcl_msg.header.stamp)

def save_tracklet_data(bag, kitti, velo_frame_id, topic):
    print("Exporting tracklet data...")
    try:
        from zzz_perception_msgs.msg import ObjectClass, TrackingBox, TrackingBoxArray
    except ImportError:
        print("!!! Cannot import zzz_perception_msgs! Tracklets are ignored !!!")
        return

    for timestamp, tracks in tqdm.tqdm(izip(kitti.velo_timestamps, kitti.tracklets), unit="Frame",
        desc="Writing tracklets", leave=False, dynamic_ncols=True, total=len(kitti.velo_timestamps)):

        array = TrackingBoxArray()
        array.header.frame_id = velo_frame_id
        array.header.stamp = rospy.Time.from_sec(timestamp.astype('O') / 1e9)
        for track in tracks:
            msg = TrackingBox()

            msg.bbox.pose.pose.position.x = track.tx
            msg.bbox.pose.pose.position.y = track.ty
            msg.bbox.pose.pose.position.z = track.tz
            q = tf.transformations.quaternion_from_euler(track.rx, track.ry, track.rz)
            msg.bbox.pose.pose.orientation.x = q[0]
            msg.bbox.pose.pose.orientation.y = q[1]
            msg.bbox.pose.pose.orientation.z = q[2]
            msg.bbox.pose.pose.orientation.w = q[3]
            msg.bbox.pose.covariance = [0] * 36

            msg.bbox.dimension.length_x = track.w
            msg.bbox.dimension.length_y = track.l
            msg.bbox.dimension.length_z = track.h
            msg.bbox.dimension.covariance = [0] * 9
            # Infinity covariance indicates that the twist is not provided
            msg.twist.covariance = np.diag([np.inf] * 6).flatten().tolist()
            msg.accel.covariance = np.diag([np.inf] * 6).flatten().tolist()

            cat = ObjectClass()
            cat.classid = driver.LABELS_MAP[track.objectType]
            cat.comments = track.objectType
            cat.score = 1
            msg.classes.append(cat)
            msg.uid = track.id

            states = {
                "pose_state": driver.POSE_STATES[int(track.state)],
                "occlusion_state": driver.OCCLUSION_STATES[int(track.occlusion)],
                "occlusion_keyframe": True if track.occlusion_kf > 0 else False,
                "truncation_state": driver.TRUNCATION_STATES[int(track.truncation)]
            }
            msg.comments = json.dumps(states, separators=(',', ':'))
            array.targets.append(msg)

        bag.write(topic + '/tracklets', array, t=array.header.stamp)

def get_static_transform(from_frame_id, to_frame_id, transform):
    t = transform[0:3, 3]
    q = tf.transformations.quaternion_from_matrix(transform)
    tf_msg = TransformStamped()
    tf_msg.header.frame_id = from_frame_id
    tf_msg.child_frame_id = to_frame_id
    tf_msg.transform.translation.x = float(t[0])
    tf_msg.transform.translation.y = float(t[1])
    tf_msg.transform.translation.z = float(t[2])
    tf_msg.transform.rotation.x = float(q[0])
    tf_msg.transform.rotation.y = float(q[1])
    tf_msg.transform.rotation.z = float(q[2])
    tf_msg.transform.rotation.w = float(q[3])
    return tf_msg

def inv_transform(transform):
    "Invert rigid body transformation matrix"
    R = transform[0:3, 0:3]
    t = transform[0:3, 3]
    t_inv = -1 * R.T.dot(t)
    transform_inv = np.eye(4)
    transform_inv[0:3, 0:3] = R.T
    transform_inv[0:3, 3] = t_inv
    return transform_inv

# Write static transforms every second. Theoretically static transforms should not be updated in a high frequency
def save_static_transforms(bag, transforms, timestamps, interval=1):
    print("Exporting static transformations...")
    time = timestamps[0].astype('O') / 1e9
    tmax = timestamps[-1].astype('O') / 1e9

    while time < tmax:
        tfm = TFMessage()
        for transform in transforms:
            t = get_static_transform(from_frame_id=transform[0], to_frame_id=transform[1], transform=transform[2])
            t.header.stamp = rospy.Time.from_sec(time)
            tfm.transforms.append(t)
        bag.write('/tf_static', tfm, t=rospy.Time.from_sec(time))
        time += interval

def save_gps_fix_data(bag, kitti, gps_frame_id, topic):
    for timestamp, oxts in izip(kitti.oxts_timestamps, kitti.oxts):
        navsatfix_msg = NavSatFix()
        navsatfix_msg.header.frame_id = gps_frame_id
        navsatfix_msg.header.stamp = rospy.Time.from_sec(timestamp.astype('O') / 1e9)
        navsatfix_msg.latitude = oxts.packet.lat
        navsatfix_msg.longitude = oxts.packet.lon
        navsatfix_msg.altitude = oxts.packet.alt
        navsatfix_msg.status.service = 1
        bag.write(topic, navsatfix_msg, t=navsatfix_msg.header.stamp)

def save_gps_vel_data(bag, kitti, gps_frame_id, topic):
    for timestamp, oxts in izip(kitti.oxts_timestamps, kitti.oxts):
        twist_msg = TwistStamped()
        twist_msg.header.frame_id = gps_frame_id
        twist_msg.header.stamp = rospy.Time.from_sec(timestamp.astype('O') / 1e9)
        twist_msg.twist.linear.x = oxts.packet.vf
        twist_msg.twist.linear.y = oxts.packet.vl
        twist_msg.twist.linear.z = oxts.packet.vu
        twist_msg.twist.angular.x = oxts.packet.wf
        twist_msg.twist.angular.y = oxts.packet.wl
        twist_msg.twist.angular.z = oxts.packet.wu
        bag.write(topic, twist_msg, t=twist_msg.header.stamp)

def arg_parser():
    parser = argparse.ArgumentParser(description="Convert KITTI dataset to ROS bag file the easy way!")
    parser.add_argument("type", choices=["sync", "extract", "odometry"], help=\
        "KITTI dataset type")
    parser.add_argument("dir", default=os.getcwd(), help=\
        "base directory of the dataset, if no directory passed the default is current working directory")
    parser.add_argument("-z", "--inzip", action='store_true', help=\
        "load data directly from KITTI zip file")
    parser.add_argument("-s", "--sequence", type=int, help=\
        "sequence of the dataset. Option available in raw and odometry dataset")
    parser.add_argument("-c", "--compression", default="none", choices=["none", "bz2", "lz4"], help=\
        "Compression algorithm for the bag. No compression is performed by default")
    parser.add_argument("-l", "--labels", action='store_true', help=\
        "Load tracklets into rosbag. This requires zzz_perception_msgs and only work for {raw sync, object} dataset")

def main():
    args = arg_parser().parse_args()

    # Compression type
    if args.compression == "none":
        compression = rosbag.Compression.NONE
    elif args.compression == "bz2":
        compression = rosbag.Compression.BZ2
    elif args.compression == "lz4":
        compression = rosbag.Compression.LZ4
    
    # Frame ids
    cameras = [
        (0, 'camera_gray_left', '/kitti/camera_gray_left'),
        (1, 'camera_gray_right', '/kitti/camera_gray_right'),
        (2, 'camera_color_left', '/kitti/camera_color_left'),
        (3, 'camera_color_right', '/kitti/camera_color_right')
    ]

    imu_frame_id = 'imu_link'
    imu_topic = '/kitti/oxts/imu'
    gps_fix_topic = '/kitti/oxts/gps/fix'
    gps_vel_topic = '/kitti/oxts/gps/vel'
    velo_frame_id = 'velo_link'
    velo_topic = '/kitti/velo'

    bag = rosbag.Bag("kitti_{}_{}.bag".format(args.type, args.sequence), 'w', compression=compression)

    # ---------- Convert raw data ----------
    if args.type == "sync" or args.type == "extract":
        if args.sequence == None:
            raise KeyError("Sequence option is not given. It is mandatory for raw dataset. Program will terminate!")
        
        kitti = driver.RawDataset(args.dir, args.sequence, args.type, inzip=args.inzip)

        T_base_link_to_imu = np.eye(4, 4)
        T_base_link_to_imu[0:3, 3] = [-2.71/2.0-0.05, 0.32, 0.93]

        # tf_static
        transforms = [
            ('base_link', imu_frame_id, T_base_link_to_imu),
            (imu_frame_id, velo_frame_id, inv_transform(kitti.calib['T_velo_imu'])),
            (imu_frame_id, cameras[0][1], inv_transform(kitti.calib['T_cam0_imu'])),
            (imu_frame_id, cameras[1][1], inv_transform(kitti.calib['T_cam1_imu'])),
            (imu_frame_id, cameras[2][1], inv_transform(kitti.calib['T_cam2_imu'])),
            (imu_frame_id, cameras[3][1], inv_transform(kitti.calib['T_cam3_imu']))
        ]

        # Export
        save_static_transforms(bag, transforms, kitti.oxts_timestamps)
        save_dynamic_tf(bag, kitti, args.type)
        save_imu_data(bag, kitti, imu_frame_id, imu_topic)
        save_gps_fix_data(bag, kitti, imu_frame_id, gps_fix_topic)
        save_gps_vel_data(bag, kitti, imu_frame_id, gps_vel_topic)
        if args.type == "sync" and args.labels:
            save_tracklet_data(bag, kitti, velo_frame_id, '/kitti')
        
        # Export large data
        for camera in cameras:
            save_camera_data(bag, kitti, args.type, camera=camera[0], camera_frame_id=camera[1], topic=camera[2])
        save_velo_data(bag, kitti, velo_frame_id, velo_topic)

    # ---------- Convert raw data ----------
    elif args.type == "odometry":
        if args.sequence == None:
            raise KeyError("Sequence option is not given. It is mandatory for odometry dataset. Program will terminate!")
                    
        kitti = driver.OdometryDataset(args.dir, args.sequence, inzip=args.inzip)

        # TODO: add support for lidar
        # TODO: add static transformations
        save_dynamic_tf(bag, kitti, args.type)
        for camera in cameras:
            save_camera_data(bag, kitti, args.type, camera=camera[0], camera_frame_id=camera[1], topic=camera[2])

    print("==========   Bag review   ==========")
    print(bag)
    bag.close()
    kitti.close()

if __name__ == "__main__":
    main()
